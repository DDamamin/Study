# 활성화 함수

노드로 들어온 값들을 더한 후 다음 레이어로 전달하지 않고 비선형 함수에 통과시키는데 이 비선형 함수가 활성화 함수다.

선형함수가 아닌 비선형 함수인 이유는 네트워크를 깊게 하는데 의미를 주기 위함인데 이는 더 복잡한 문제를 풀 수 있게 만들어 준다. (직관적으로 생각하면 직선인 선형함수 보다 훨씬 복잡한 비선형 함수를 사용하는 것이다.) 지난번 단순한 퍼셉트론으로는 XOR게이트를 만들지 못했지만 여러 퍼셉트론을 이어 XOR 게이트를 구현했다. 이는 비선형 구조를 띄었기 때문에 가능한 것이다.

활성화 함수로는 여러 가지가 있다.

- 시그모이드(0~1)
- 계단함수(0또는 1)

- reLu(0보다 작으면 0 1보다 크면 그냥 그 수)
- 등등